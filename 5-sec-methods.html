<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Methods | slapnap: Super LeArner Prediction of NAb Panels</title>
  <meta name="description" content="5 Methods | slapnap: Super LeArner Prediction of NAb Panels" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Methods | slapnap: Super LeArner Prediction of NAb Panels" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Methods | slapnap: Super LeArner Prediction of NAb Panels" />
  
  
  

<meta name="author" content="David Benkeser, Brian D. Williamson, Craig A. Magaret, Sohail Nizam, Peter B. Gilbert" />


<meta name="date" content="2020-06-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="4-sec-examples.html"/>
<link rel="next" href="6-sec-report.html"/>
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  CommonHTML: {
    scale: 90,
    linebreaks: {
      automatic: true
    }
  },
  SVG: {
    linebreaks: {
      automatic: true
    }
  }, 
  displayAlign: "left"
  });
</script>
<script type="text/javascript"
	src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script><!-- see also '_output.yaml'
src="https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"
src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML" 
src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
-->


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="slapnap_style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="https://hub.docker.com/r/slapnap/slapnap">slapnap</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="1-sec-docker.html"><a href="1-sec-docker.html"><i class="fa fa-check"></i><b>1</b> Docker</a></li>
<li class="chapter" data-level="2" data-path="2-sec-catnap.html"><a href="2-sec-catnap.html"><i class="fa fa-check"></i><b>2</b> CATNAP</a></li>
<li class="chapter" data-level="3" data-path="3-sec-runningcontainer.html"><a href="3-sec-runningcontainer.html"><i class="fa fa-check"></i><b>3</b> Running <code>slapnap</code></a><ul>
<li class="chapter" data-level="3.1" data-path="3-sec-runningcontainer.html"><a href="3-sec-runningcontainer.html#sec:opts"><i class="fa fa-check"></i><b>3.1</b> <code>slapnap</code> run options</a></li>
<li class="chapter" data-level="3.2" data-path="3-sec-runningcontainer.html"><a href="3-sec-runningcontainer.html#returning-output"><i class="fa fa-check"></i><b>3.2</b> Returning output</a><ul>
<li class="chapter" data-level="3.2.1" data-path="3-sec-runningcontainer.html"><a href="3-sec-runningcontainer.html#sec:mounting"><i class="fa fa-check"></i><b>3.2.1</b> Mounting a local directory</a></li>
<li class="chapter" data-level="3.2.2" data-path="3-sec-runningcontainer.html"><a href="3-sec-runningcontainer.html#sec:viewreport"><i class="fa fa-check"></i><b>3.2.2</b> Viewing report in browser</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-sec-examples.html"><a href="4-sec-examples.html"><i class="fa fa-check"></i><b>4</b> Examples</a><ul>
<li class="chapter" data-level="4.1" data-path="4-sec-examples.html"><a href="4-sec-examples.html#basic-call-to-slapnap"><i class="fa fa-check"></i><b>4.1</b> Basic call to <code>slapnap</code></a></li>
<li class="chapter" data-level="4.2" data-path="4-sec-examples.html"><a href="4-sec-examples.html#sec:webbrowse"><i class="fa fa-check"></i><b>4.2</b> Viewing report in browser</a></li>
<li class="chapter" data-level="4.3" data-path="4-sec-examples.html"><a href="4-sec-examples.html#super-learning"><i class="fa fa-check"></i><b>4.3</b> Super learning</a></li>
<li class="chapter" data-level="4.4" data-path="4-sec-examples.html"><a href="4-sec-examples.html#train-an-algorithm"><i class="fa fa-check"></i><b>4.4</b> Train an algorithm</a></li>
<li class="chapter" data-level="4.5" data-path="4-sec-examples.html"><a href="4-sec-examples.html#pull-and-clean-data"><i class="fa fa-check"></i><b>4.5</b> Pull and clean data</a></li>
<li class="chapter" data-level="4.6" data-path="4-sec-examples.html"><a href="4-sec-examples.html#interactive-sessions"><i class="fa fa-check"></i><b>4.6</b> Interactive sessions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-sec-methods.html"><a href="5-sec-methods.html"><i class="fa fa-check"></i><b>5</b> Methods</a><ul>
<li class="chapter" data-level="5.1" data-path="5-sec-methods.html"><a href="5-sec-methods.html#sec:outcomedefs"><i class="fa fa-check"></i><b>5.1</b> Outcomes</a><ul>
<li class="chapter" data-level="5.1.1" data-path="5-sec-methods.html"><a href="5-sec-methods.html#single-bnab"><i class="fa fa-check"></i><b>5.1.1</b> Single bNAb</a></li>
<li class="chapter" data-level="5.1.2" data-path="5-sec-methods.html"><a href="5-sec-methods.html#multiple-bnabs"><i class="fa fa-check"></i><b>5.1.2</b> Multiple bNAbs</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5-sec-methods.html"><a href="5-sec-methods.html#sec:learnerdetails"><i class="fa fa-check"></i><b>5.2</b> Learners</a></li>
<li class="chapter" data-level="5.3" data-path="5-sec-methods.html"><a href="5-sec-methods.html#sec:sldetails"><i class="fa fa-check"></i><b>5.3</b> Super learner</a></li>
<li class="chapter" data-level="5.4" data-path="5-sec-methods.html"><a href="5-sec-methods.html#variable-importance"><i class="fa fa-check"></i><b>5.4</b> Variable importance</a><ul>
<li class="chapter" data-level="5.4.1" data-path="5-sec-methods.html"><a href="5-sec-methods.html#sec:biolimp"><i class="fa fa-check"></i><b>5.4.1</b> Biological importance</a></li>
<li class="chapter" data-level="5.4.2" data-path="5-sec-methods.html"><a href="5-sec-methods.html#predictive-importance"><i class="fa fa-check"></i><b>5.4.2</b> Predictive importance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-sec-report.html"><a href="6-sec-report.html"><i class="fa fa-check"></i><b>6</b> Report</a></li>
<li class="chapter" data-level="7" data-path="7-sec-data.html"><a href="7-sec-data.html"><i class="fa fa-check"></i><b>7</b> Data</a></li>
<li class="chapter" data-level="8" data-path="8-sec-refs.html"><a href="8-sec-refs.html"><i class="fa fa-check"></i><b>8</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><code>slapnap</code>: Super LeArner Prediction of NAb Panels</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec:methods" class="section level1">
<h1><span class="header-section-number">5</span> Methods</h1>
<div id="sec:outcomedefs" class="section level2">
<h2><span class="header-section-number">5.1</span> Outcomes</h2>
<div id="single-bnab" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Single bNAb</h3>
<p>If a single bNAb or combination of bNAbs that are measured directly in the CATNAP data is requested (i.e., the <code>nab</code> option is a single string of a single bNAb or measured combination of bNAbs from the CATNAP database), then the possible outcomes are:</p>
<ul>
<li><code>ic50</code> = IC<span class="math inline">\(_{50}\)</span>: the half maximal inhibitory concentration;</li>
<li><code>ic80</code> = IC<span class="math inline">\(_{80}\)</span>: the 80% maximal inhibitory concentration;</li>
<li><code>iip</code> = IIP <span class="citation">(Shen et al. <a href="#ref-shen2008dose">2008</a>, <span class="citation">Wagh et al. (<a href="#ref-wagh2016optimal">2016</a>)</span>)</span>: the instantaneous inhibitory potential, computed as <span class="math display">\[ \frac{10^m}{\mbox{IC$_{50}$}^m + 10^m} \ , \]</span> where <span class="math inline">\(m = \mbox{log}_{10}(4) / (\mbox{log}_{10}(\mbox{IC}_{80}) - \mbox{log}_{10}(\mbox{IC}_{50}))\)</span>; and</li>
<li><code>sens</code> = sensitivity: the binary indicator that IC<span class="math inline">\(_{50}\)</span> <span class="math inline">\(&lt;\)</span> <code>sens_thresh</code>, the user-specified sensitivity threshold.</li>
</ul>
</div>
<div id="multiple-bnabs" class="section level3">
<h3><span class="header-section-number">5.1.2</span> Multiple bNAbs</h3>
<p>If multiple bNAbs are requested (i.e., the <code>nab</code> option is a semi-colon separated string of more than one bNAb from CATNAP), then the possible <code>outcomes</code> that can be requested are:</p>
<ul>
<li><code>ic50</code> = estimated IC<span class="math inline">\(_{50}\)</span>: for <span class="math inline">\(J\)</span> bNAbs, <span class="math display">\[ \mbox{estimated IC}_{50} = \left( \sum_{j=1}^J \mbox{IC}_{50,j}^{-1} \right)^{-1} \ , \]</span> where IC<span class="math inline">\(_{50,j}\)</span> denotes the measured IC<span class="math inline">\(_{50}\)</span> for antibody <span class="math inline">\(j\)</span> <span class="citation">(Wagh et al. <a href="#ref-wagh2016optimal">2016</a>)</span>;</li>
<li><code>ic80</code> = estimated IC<span class="math inline">\(_{80}\)</span>: for <span class="math inline">\(J\)</span> bNAbs, <span class="math display">\[ \mbox{estimated IC}_{80} = \left( \sum_{j=1}^J \mbox{IC}_{80,j}^{-1} \right)^{-1} \ , \]</span> where IC<span class="math inline">\(_{80,j}\)</span> denotes the measured IC<span class="math inline">\(_{80}\)</span> for antibody <span class="math inline">\(j\)</span> <span class="citation">(Wagh et al. <a href="#ref-wagh2016optimal">2016</a>)</span>;</li>
<li><code>iip</code> = IIP: computed as <span class="math display">\[ \frac{10^m}{\mbox{estimated IC$_{50}$}^m + 10^m} \ , \]</span> where <span class="math inline">\(m = \mbox{log}_{10}(4) / (\mbox{log}_{10}(\mbox{estimated IC}_{80}) - \mbox{log}_{10}(\mbox{estimated IC}_{50}))\)</span>; and</li>
<li><code>estsens</code> = estimated sensitivity: the binary indicator that estimated IC<span class="math inline">\(_{50}\)</span> (defined above) is less than <code>sens_thresh</code>; and</li>
<li><code>multsens</code> = multiple sensitivity: the binary indicator that measured IC<span class="math inline">\(_{50}\)</span> is less than the sensitivity threshold (<code>sens_thresh</code>) for a number of bNAbs defined by <code>multsens_nab</code>.</li>
</ul>
</div>
</div>
<div id="sec:learnerdetails" class="section level2">
<h2><span class="header-section-number">5.2</span> Learners</h2>
<p>There are three possible <code>learners</code> available in <code>slapnap</code>: random forests <span class="citation">(Breiman <a href="#ref-breiman2001">2001</a>)</span>, as implemented in the <code>R</code> package <code>ranger</code> <span class="citation">(Wright and Ziegler <a href="#ref-rangerpkg">2017</a>)</span>; elastic net <span class="citation">(Zou and Hastie <a href="#ref-zou2005">2005</a>)</span> as implemented in <code>glmnet</code> <span class="citation">(J. Friedman, Hastie, and Tibshirani <a href="#ref-glmnetpkg">2010</a>)</span>; and boosted trees <span class="citation">(J. H. Friedman <a href="#ref-friedman2001">2001</a>; T. Chen and Guestrin <a href="#ref-chen2016">2016</a>)</span> as implemented in <code>xgboost</code> <span class="citation">(T. Chen et al. <a href="#ref-xgboostpkg">2019</a>)</span>.</p>
<p>For each <code>learner</code>, there is a <code>default</code> choice of tuning parameters that is implemented if <code>cvtune=&quot;FALSE&quot;</code>. If instead <code>cvtune=&quot;TRUE&quot;</code>, then there are several choices of tuning parameters that are evaluated using <code>nfold</code> cross validation, Table <a href="5-sec-methods.html#tab:learners">5.1</a>.</p>
<table>
<caption><span id="tab:learners">Table 5.1: </span>Labels for <code>learners</code> in report and description of their respective tuning parameters</caption>
<thead>
<tr class="header">
<th align="left"><code>learner</code></th>
<th align="left">Tuning parameters</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>rf_default</code></td>
<td align="left"><code>mtry</code> equal to square root of number of predictors</td>
</tr>
<tr class="even">
<td align="left"><code>rf_1</code></td>
<td align="left"><code>mtry</code> equal to one-half times square root of number of predictors</td>
</tr>
<tr class="odd">
<td align="left"><code>rf_2</code></td>
<td align="left"><code>mtry</code> equal to two times square root of number of predictors</td>
</tr>
<tr class="even">
<td align="left"><code>xgboost_default</code></td>
<td align="left">maximum tree depth equal to 4</td>
</tr>
<tr class="odd">
<td align="left"><code>xgboost_1</code></td>
<td align="left">maximum tree depth equal to 2</td>
</tr>
<tr class="even">
<td align="left"><code>xgboost_2</code></td>
<td align="left">maximum tree depth equal to 6</td>
</tr>
<tr class="odd">
<td align="left"><code>xgboost_3</code></td>
<td align="left">maximum tree depth equal to 8</td>
</tr>
<tr class="even">
<td align="left"><code>lasso_default</code></td>
<td align="left"><span class="math inline">\(\lambda\)</span> selected by 5-fold CV and <span class="math inline">\(\alpha\)</span> equal to 0</td>
</tr>
<tr class="odd">
<td align="left"><code>lasso_1</code></td>
<td align="left"><span class="math inline">\(\lambda\)</span> selected by 5-fold CV and <span class="math inline">\(\alpha\)</span> equal to 0.25</td>
</tr>
<tr class="even">
<td align="left"><code>lasso_2</code></td>
<td align="left"><span class="math inline">\(\lambda\)</span> selected by 5-fold CV and <span class="math inline">\(\alpha\)</span> equal to 0.5</td>
</tr>
<tr class="odd">
<td align="left"><code>lasso_3</code></td>
<td align="left"><span class="math inline">\(\lambda\)</span> selected by 5-fold CV and <span class="math inline">\(\alpha\)</span> equal to 0.75</td>
</tr>
</tbody>
</table>
<p>Tuning parameters not mentioned in the table are set as follows:</p>
<ul>
<li><code>rf</code>: <code>num.trees = 500</code>, <code>min.node.size = 5</code> for continuous outcomes and <code>= 1</code> for binary outcomes;</li>
<li><code>xgboost</code>: <code>nrounds = 1000</code>, <code>eta = 0.1</code>, <code>min_child_weight = 10</code>, objective = <code>binary:logistic</code> for binary outcomes and <code>objective=reg:squarederror</code> for continuous outcomes.</li>
</ul>
</div>
<div id="sec:sldetails" class="section level2">
<h2><span class="header-section-number">5.3</span> Super learner</h2>
<p>If multiple <code>learners</code> are specified, then a super learner ensemble <span class="citation">(M. J. van der Laan, Polley, and Hubbard <a href="#ref-vanderlaan2007">2007</a>)</span> is constructed using <code>nfold</code> cross validation, as implemented in the <code>R</code> package <code>SuperLearner</code> <span class="citation">(E. Polley et al. <a href="#ref-superlearnerpkg">2019</a>)</span>. Specifically, the data are randomly partitioned into <code>nfold</code> chunks of approximately equal size. For binary outcomes, this partitioning is done in such a way as to ensure an approximately even number of sensitive/resistant pseudoviruses in each chunk. A so-called super learner <em>library</em> of candidate algorithms is constructed by including different <code>learners</code>:</p>
<ul>
<li>the algorithm <code>mean</code>, which reports back the sample mean as prediction for all observations is always included;</li>
<li>if <code>cvtune=&quot;FALSE&quot;</code> then the <code>default</code> version of each <code>learner</code> (Section <a href="5-sec-methods.html#sec:learnerdetails">5.2</a>) is included;</li>
<li>if <code>cvtune=&quot;TRUE&quot;</code> then each choice of tuning parameters for the selected <code>learners</code> in Table <a href="5-sec-methods.html#tab:learners">5.1</a> is included.</li>
</ul>
<p>The cross-validated risk of each algorithm in the library is computed. For binary outcomes, mean negative log-likelihood loss is used; for continuous outcomes, mean squared-error is used. The single algorithm with the smallest cross-validated risk is reported as the <code>cv selector</code> (also known as the <em>discrete</em> super learner). The super learner ensemble is constructed by selecting convex weights (i.e., each algorithm is assigned a non-negative weight and the weights sum to one) that minimize cross-validated risk.</p>
<p>When <code>cvperf=&quot;TRUE&quot;</code> and a super learner is constructed, an additional layer of cross validation is used to evaluate the predictive performance of the super learner and of the <code>cv selector</code>.</p>
</div>
<div id="variable-importance" class="section level2">
<h2><span class="header-section-number">5.4</span> Variable importance</h2>
<p>If <code>importance_grp</code> or <code>importance_ind</code> is specified, variable importance estimates are computed based on the <code>learners</code>. Both biological and prediction importance can be obtained; we discuss each in the following two sections.</p>
<div id="sec:biolimp" class="section level3">
<h3><span class="header-section-number">5.4.1</span> Biological importance</h3>
<p>Biological importance may be obtained by specifying <code>importance_grp</code>, <code>importance_ind</code>, or both. We provide two types of biological importance: marginal and conditional, accessed by passing <code>&quot;marg&quot;</code> and <code>&quot;cond&quot;</code>, respectively, to one of the importance variables. Both types of biological importance are based on the population prediction potential of features <span class="citation">(Williamson et al. <a href="#ref-williamson2020">2020</a>)</span>, as implemented in the <code>R</code> package <code>vimp</code> <span class="citation">(B. D. Williamson, Simon, and Carone <a href="#ref-vimppkg">2020</a>)</span>. We measure prediction potential using nonparametric <span class="math inline">\(R^2\)</span> for continuous outcomes (i.e., IC<span class="math inline">\(_{50}\)</span>, IC<span class="math inline">\(_{80}\)</span>, or IIP) and using the nonparametric area under the receiver operating characteristic curve (AUC) for binary outcomes (i.e., sensitivity, estimated sensitivity, or multiple sensitivity). In both marginal and conditional importance, we compare the population prediction potential including the feature(s) of interest to the population prediction potential excluding the feature(s) or interest; this provides a measure of the biological importance of the feature(s). The two types of biological importance differ only in the other adjustment variables that we consider: conditional importance compares the prediction potential of all features to the prediction potential of all features excluding the feature(s) of interest, and thus importance must be interpreted conditionally; whereas marginal importance compares the prediction potential of the feature(s) of interest plus geographic confounders to the prediction potential of the geographic confounders alone.</p>
<p>Both marginal and conditional biological importance can be computed for groups of features or individual features. The available feature groups are detailed in Section <a href="7-sec-data.html#sec:data">7</a>. Execution time may increase when biological importance is requested, depending upon the other options passed to <code>slapnap</code>: a separate <code>learner</code> (or super learner ensemble) must be trained for each feature group (or individual feature) of interest. Marginal importance tends to be computed more quickly than conditional importance, but both types of importance provide useful information about the population of interest and the underlying biology.</p>
<p>If biological importance is requested, then point estimates, confidence intervals, and p-values (for a test of the null hypothesis that the biological importance is equal to zero) will be computed and displayed for each feature or group of features of interest. All results are based on first creating two independent splits of the data: the population prediction potential including the feature(s) of interest is estimated on one half of the data, while the population prediction potential excluding the feature(s) of interest is estimated on the remaining half. This ensures that the procedure has the desired type I error rate.</p>
<p>In the following command, we request marginal biological importance for the feature groups defined in Section <a href="7-sec-data.html#sec:data">7</a>. We do not specify a super learner ensemble to reduce computation time; however, in most problems we recommend an ensemble to protect against model misspecification.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker</span> run -v /path/to/local/dir:/home/output \
           -e importance_grp=<span class="st">&quot;marg&quot;</span> \
           slapnap/slapnap</code></pre></div>
<p>The raw <code>R</code> objects (saved as <code>.rds</code> files) containing the point estimates, confidence intervals, and p-values for biological importance can be saved by passing <code>&quot;vimp&quot;</code> to <code>return</code>.</p>
</div>
<div id="predictive-importance" class="section level3">
<h3><span class="header-section-number">5.4.2</span> Predictive importance</h3>
<p><code>learner</code>-level predictive importance may be obtained by including <code>&quot;pred&quot;</code> in the <code>importance_ind</code> option. If a single <code>learner</code> is fit, then the predictive importance is the <code>R</code> default for that type of learner:</p>
<ul>
<li><code>rf</code>: the <code>impurity</code> importance from <code>ranger</code> <span class="citation">(Wright and Ziegler <a href="#ref-rangerpkg">2017</a>)</span> is returned. The impurity importance for a given feature is computed by taking a normalized sum of the decrease in impurity (i.e., Gini index for binary outcomes; mean squared-error for continuous outcomes) over all nodes in the forest at which a split on that feature has been conducted.</li>
<li><code>xgboost</code>: the <code>gain</code> importance from <code>xgboost</code> <span class="citation">(T. Chen et al. <a href="#ref-xgboostpkg">2019</a>)</span> is returned. Interpretation is essentially the same as for <code>rf</code>'s <code>impurity</code> importance.</li>
<li><code>lasso</code>: the absolute value of the estimated regression coefficient at the cross-validation-selected <span class="math inline">\(\lambda\)</span> is returned.</li>
</ul>
<p>Note that these importance measures each have important limitations: the <code>rf</code> and <code>xgboost</code> measures will tend to favor features with many levels, while the <code>lasso</code> variable importance will tend to favor features with few levels. Nevertheless, these commonly reported measures can provide some insight into how a given learner is making predictions.</p>
<p>If multiple <code>learners</code> are used, and thus a super learner is constructed, then the importance measures for the <code>learner</code> with the highest weight in the super learner are reported.</p>
<p>If a single <code>learner</code> is used, but <code>cvtune=&quot;TRUE&quot;</code> then importance measures for the <code>cv selector</code> are reported.</p>
<p>In the following command, we request predictive importance for a simple scenario. Predictive importance is displayed for the top 15 features.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker</span> run -v /path/to/local/dir:/home/output \
           -e importance_ind=<span class="st">&quot;pred&quot;</span> \
           slapnap/slapnap</code></pre></div>
</div>
</div>
</div>
<h3> References</h3>
<div id="refs" class="references">
<div id="ref-breiman2001">
<p>Breiman, Leo. 2001. “Random Forests.” <em>Machine Learning</em> 45 (1). Springer: 5–32. doi:<a href="https://doi.org/10.1023/A:1010933404324">10.1023/A:1010933404324</a>.</p>
</div>
<div id="ref-chen2016">
<p>Chen, Tianqi, and Carlos Guestrin. 2016. “Xgboost: A Scalable Tree Boosting System.” In <em>Proceedings of the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining</em>, 785–94. doi:<a href="https://doi.org/10.1145/2939672.2939785">10.1145/2939672.2939785</a>.</p>
</div>
<div id="ref-xgboostpkg">
<p>Chen, Tianqi, Tong He, Michael Benesty, Vadim Khotilovich, Yuan Tang, Hyunsu Cho, Kailong Chen, et al. 2019. <em>xgboost: Extreme Gradient Boosting</em>. <a href="https://CRAN.R-project.org/package=xgboost" class="uri">https://CRAN.R-project.org/package=xgboost</a>.</p>
</div>
<div id="ref-friedman2001">
<p>Friedman, Jerome H. 2001. “Greedy Function Approximation: A Gradient Boosting Machine.” <em>Annals of Statistics</em>. JSTOR, 1189–1232. doi:<a href="https://doi.org/10.1214/aos/1013203451">10.1214/aos/1013203451</a>.</p>
</div>
<div id="ref-glmnetpkg">
<p>Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2010. “Regularization Paths for Generalized Linear Models via Coordinate Descent.” <em>Journal of Statistical Software</em> 33 (1): 1–22. doi:<a href="https://doi.org/10.18637/jss.v033.i01">10.18637/jss.v033.i01</a>.</p>
</div>
<div id="ref-superlearnerpkg">
<p>Polley, Eric, Erin LeDell, Chris Kennedy, and Mark van der Laan. 2019. <em>SuperLearner: Super Learner Prediction</em>. <a href="https://CRAN.R-project.org/package=SuperLearner" class="uri">https://CRAN.R-project.org/package=SuperLearner</a>.</p>
</div>
<div id="ref-shen2008dose">
<p>Shen, Lin, Susan Peterson, Ahmad R Sedaghat, Moira A McMahon, Marc Callender, Haili Zhang, Yan Zhou, et al. 2008. “Dose-Response Curve Slope Sets Class-Specific Limits on Inhibitory Potential of anti-HIV Drugs.” <em>Nature Medicine</em> 14 (7). Nature Publishing Group: 762–66. doi:<a href="https://doi.org/10.1038/nm1777">10.1038/nm1777</a>.</p>
</div>
<div id="ref-vanderlaan2007">
<p>van der Laan, Mark J, Eric C Polley, and Alan E Hubbard. 2007. “Super Learner.” <em>Statistical Applications in Genetics and Molecular Biology</em> 6 (1). De Gruyter. doi:<a href="https://doi.org/10.2202/1544-6115.1309">10.2202/1544-6115.1309</a>.</p>
</div>
<div id="ref-wagh2016optimal">
<p>Wagh, Kshitij, Tanmoy Bhattacharya, Carolyn Williamson, Alex Robles, Madeleine Bayne, Jetta Garrity, Michael Rist, et al. 2016. “Optimal Combinations of Broadly Neutralizing Antibodies for Prevention and Treatment of HIV-1 Clade C Infection.” <em>PLoS Pathogens</em> 12 (3). Public Library of Science. doi:<a href="https://doi.org/10.1371/journal.ppat.1005520">10.1371/journal.ppat.1005520</a>.</p>
</div>
<div id="ref-williamson2020">
<p>Williamson, Brian D, Peter B Gilbert, Noah R Simon, and Marco Carone. 2020. “A Unified Approach for Inference on Algorithm-Agnostic Variable Importance.” <em>arXiv Preprint</em>. <a href="https://arxiv.org/abs/2004.03683" class="uri">https://arxiv.org/abs/2004.03683</a>.</p>
</div>
<div id="ref-vimppkg">
<p>Williamson, Brian D., Noah Simon, and Marco Carone. 2020. “vimp: Perform Inference on Algorithm-Agnostic Variable Importance.” <a href="https://CRAN.R-project.org/package=vimp" class="uri">https://CRAN.R-project.org/package=vimp</a>.</p>
</div>
<div id="ref-rangerpkg">
<p>Wright, Marvin N., and Andreas Ziegler. 2017. “ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R.” <em>Journal of Statistical Software</em> 77 (1): 1–17. doi:<a href="https://doi.org/10.18637/jss.v077.i01">10.18637/jss.v077.i01</a>.</p>
</div>
<div id="ref-zou2005">
<p>Zou, Hui, and Trevor Hastie. 2005. “Regularization and Variable Selection via the Elastic Net.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 67 (2). Wiley Online Library: 301–20. doi:<a href="https://doi.org/10.1111/j.1467-9868.2005.00503.x">10.1111/j.1467-9868.2005.00503.x</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="4-sec-examples.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="6-sec-report.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_hightlight": true,
"toolbar": {
"position": "static"
},
"edit": null,
"download": "pdf",
"search": true,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
}
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
